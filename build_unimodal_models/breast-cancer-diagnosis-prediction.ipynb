{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7414986,"sourceType":"datasetVersion","datasetId":4313485}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ©º Cancer Diagnosis Prediction\n\nThis project builds and evaluates multiple machine learning models for predicting **breast cancer diagnosis (Benign vs. Malignant)** using a clinical dataset.  \nThe dataset includes demographic, tumor, and clinical features (e.g., age, menopause, tumor size, breast quadrant, history, etc.).\n\n---\n\n## ðŸ“‚ Dataset\n- Source: `cancer_diagnosis_data.csv`\n- Shape: **213 samples Ã— 11 columns**\n- Target: `Diagnosis Result` (Benign / Malignant)\n- Example columns:\n  - `Age`\n  - `Menopause`\n  - `Tumor Size (cm)`\n  - `Breast Quadrant`\n  - `History`\n  - `Diagnosis Result` (target)\n\n---\n\n## âš™ï¸ Preprocessing\n1. **Missing values** handled:\n   - Numeric â†’ median imputation\n   - Categorical â†’ most frequent imputation\n2. **Normalization**: StandardScaler on numeric features\n3. **One-Hot Encoding**: categorical features converted to binary features\n4. **Train/Validation/Test split**:  \n   - Train: 64%  \n   - Validation: 16%  \n   - Test: 20%\n\n---\n\n## ðŸ¤– Models Trained\nThe following models were benchmarked:\n\n- Logistic Regression\n- Random Forest\n- Support Vector Machine (RBF Kernel)\n- XGBoost\n- K-Nearest Neighbors (KNN)\n- Naive Bayes\n- Gradient Boosting (sklearn)\n\n---\n\n## ðŸ“Š Results\n\n| Model               | Validation Accuracy | Test Accuracy |\n|----------------------|---------------------|---------------|\n| Logistic Regression  | 0.9706              | **0.9070**    |\n| Random Forest        | 0.9706              | 0.8837        |\n| SVM (RBF Kernel)     | 0.9706              | **0.9070**    |\n| XGBoost              | 0.8824              | 0.7907        |\n| KNN                  | 0.9412              | **0.9070**    |\n| Naive Bayes          | 0.9706              | **0.9070**    |\n| Gradient Boosting    | 0.9118              | 0.7907        |\n\nâœ… **Best Model:** Logistic Regression (Validation Accuracy = **97.06%**)  \nðŸŽ‰ Saved as `best_model.pkl`","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:55.491493Z","iopub.execute_input":"2025-09-02T15:45:55.491864Z","iopub.status.idle":"2025-09-02T15:45:56.922662Z","shell.execute_reply.started":"2025-09-02T15:45:55.491836Z","shell.execute_reply":"2025-09-02T15:45:56.921629Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(f\"/kaggle/input/breast-cancer-prediction/breast-cancer-dataset.csv\")  # replace with actual file name\nprint(df.head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:56.924263Z","iopub.execute_input":"2025-09-02T15:45:56.924760Z","iopub.status.idle":"2025-09-02T15:45:56.982599Z","shell.execute_reply.started":"2025-09-02T15:45:56.924716Z","shell.execute_reply":"2025-09-02T15:45:56.981718Z"}},"outputs":[{"name":"stdout","text":"   S/N  Year  Age  Menopause Tumor Size (cm) Inv-Nodes Breast Metastasis  \\\n0    1  2019   40          1               2         0  Right          0   \n1    2  2019   39          1               2         0   Left          0   \n2    3  2019   45          0               4         0   Left          0   \n3    4  2019   26          1               3         0   Left          0   \n4    5  2019   21          1               1         0  Right          0   \n\n  Breast Quadrant History Diagnosis Result  \n0     Upper inner       0           Benign  \n1     Upper outer       0           Benign  \n2     Lower outer       0           Benign  \n3     Lower inner       1           Benign  \n4     Upper outer       1           Benign  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Quick check\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nColumns:\\n\", df.columns)\nprint(\"\\nSample rows:\\n\", df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:56.983387Z","iopub.execute_input":"2025-09-02T15:45:56.983622Z","iopub.status.idle":"2025-09-02T15:45:56.994958Z","shell.execute_reply.started":"2025-09-02T15:45:56.983604Z","shell.execute_reply":"2025-09-02T15:45:56.993568Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (213, 11)\n\nColumns:\n Index(['S/N', 'Year', 'Age', 'Menopause', 'Tumor Size (cm)', 'Inv-Nodes',\n       'Breast', 'Metastasis', 'Breast Quadrant', 'History',\n       'Diagnosis Result'],\n      dtype='object')\n\nSample rows:\n    S/N  Year  Age  Menopause Tumor Size (cm) Inv-Nodes Breast Metastasis  \\\n0    1  2019   40          1               2         0  Right          0   \n1    2  2019   39          1               2         0   Left          0   \n2    3  2019   45          0               4         0   Left          0   \n3    4  2019   26          1               3         0   Left          0   \n4    5  2019   21          1               1         0  Right          0   \n\n  Breast Quadrant History Diagnosis Result  \n0     Upper inner       0           Benign  \n1     Upper outer       0           Benign  \n2     Lower outer       0           Benign  \n3     Lower inner       1           Benign  \n4     Upper outer       1           Benign  \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 2. Define target and features\ntarget = \"Diagnosis Result\"\nX = df.drop(columns=[target, \"S/N\"])  # drop target + serial number\ny = df[target].map({\"Benign\": 0, \"Malignant\": 1})  # convert to numeric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:56.997052Z","iopub.execute_input":"2025-09-02T15:45:56.997430Z","iopub.status.idle":"2025-09-02T15:45:57.043514Z","shell.execute_reply.started":"2025-09-02T15:45:56.997404Z","shell.execute_reply":"2025-09-02T15:45:57.042453Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 3. Identify categorical & numeric features\ncategorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\nnumeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n\nprint(\"\\nCategorical columns:\", categorical_cols)\nprint(\"Numeric columns:\", numeric_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:57.044603Z","iopub.execute_input":"2025-09-02T15:45:57.044966Z","iopub.status.idle":"2025-09-02T15:45:57.065277Z","shell.execute_reply.started":"2025-09-02T15:45:57.044936Z","shell.execute_reply":"2025-09-02T15:45:57.064223Z"}},"outputs":[{"name":"stdout","text":"\nCategorical columns: ['Year', 'Tumor Size (cm)', 'Inv-Nodes', 'Breast', 'Metastasis', 'Breast Quadrant', 'History']\nNumeric columns: ['Age', 'Menopause']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 5. Train-validation-test split\n# First split train/test (80/20), then split train into train/val (80/20 of train)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n)\n\nprint(\"\\nDataset split:\")\nprint(\"Train:\", X_train.shape, \"Validation:\", X_val.shape, \"Test:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:57.066322Z","iopub.execute_input":"2025-09-02T15:45:57.066678Z","iopub.status.idle":"2025-09-02T15:45:57.102862Z","shell.execute_reply.started":"2025-09-02T15:45:57.066648Z","shell.execute_reply":"2025-09-02T15:45:57.101931Z"}},"outputs":[{"name":"stdout","text":"\nDataset split:\nTrain: (136, 9) Validation: (34, 9) Test: (43, 9)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 4. Preprocessing\nnumeric_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),  # handle missing\n    (\"scaler\", StandardScaler())  # normalize\n])\n\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))  # dense output\n])\n\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, numeric_cols),\n        (\"cat\", categorical_transformer, categorical_cols)\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:45:57.103799Z","iopub.execute_input":"2025-09-02T15:45:57.104059Z","iopub.status.idle":"2025-09-02T15:45:57.111138Z","shell.execute_reply.started":"2025-09-02T15:45:57.104040Z","shell.execute_reply":"2025-09-02T15:45:57.110050Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Apply preprocessing to the entire dataset (or just X_train)\nX_preprocessed = preprocessor.fit_transform(X)  # or X_train if you only want train\n\n# Get feature names\n# Numeric feature names stay the same\nnumeric_features = numeric_cols\n\n# Get the new one-hot encoded feature names\ncategorical_features = preprocessor.named_transformers_[\"cat\"][\"onehot\"].get_feature_names_out(categorical_cols)\n\n# Combine all feature names\nall_features = list(numeric_features) + list(categorical_features)\n\n# Create a DataFrame with processed data\nX_encoded_df = pd.DataFrame(X_preprocessed, columns=all_features)\n\n# Display the first 5 rows\nprint(X_encoded_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:46:08.019021Z","iopub.execute_input":"2025-09-02T15:46:08.019372Z","iopub.status.idle":"2025-09-02T15:46:08.060532Z","shell.execute_reply.started":"2025-09-02T15:46:08.019350Z","shell.execute_reply":"2025-09-02T15:46:08.058930Z"}},"outputs":[{"name":"stdout","text":"        Age  Menopause  Year_#  Year_2019  Year_2020  Tumor Size (cm)_#  \\\n0  0.015356   0.707107     0.0        1.0        0.0                0.0   \n1 -0.055749   0.707107     0.0        1.0        0.0                0.0   \n2  0.370884  -1.414214     0.0        1.0        0.0                0.0   \n3 -0.980123   0.707107     0.0        1.0        0.0                0.0   \n4 -1.335651   0.707107     0.0        1.0        0.0                0.0   \n\n   Tumor Size (cm)_1  Tumor Size (cm)_10  Tumor Size (cm)_12  \\\n0                0.0                 0.0                 0.0   \n1                0.0                 0.0                 0.0   \n2                0.0                 0.0                 0.0   \n3                0.0                 0.0                 0.0   \n4                1.0                 0.0                 0.0   \n\n   Tumor Size (cm)_14  ...  Metastasis_1  Breast Quadrant_#  \\\n0                 0.0  ...           0.0                0.0   \n1                 0.0  ...           0.0                0.0   \n2                 0.0  ...           0.0                0.0   \n3                 0.0  ...           0.0                0.0   \n4                 0.0  ...           0.0                0.0   \n\n   Breast Quadrant_Lower inner  Breast Quadrant_Lower outer  \\\n0                          0.0                          0.0   \n1                          0.0                          0.0   \n2                          0.0                          1.0   \n3                          1.0                          0.0   \n4                          0.0                          0.0   \n\n   Breast Quadrant_Upper inner  Breast Quadrant_Upper outer  \\\n0                          1.0                          0.0   \n1                          0.0                          1.0   \n2                          0.0                          0.0   \n3                          0.0                          0.0   \n4                          0.0                          1.0   \n\n   Breast Quadrant_Upper outer   History_#  History_0  History_1  \n0                           0.0        0.0        1.0        0.0  \n1                           0.0        0.0        1.0        0.0  \n2                           0.0        0.0        1.0        0.0  \n3                           0.0        0.0        0.0        1.0  \n4                           0.0        0.0        0.0        1.0  \n\n[5 rows x 37 columns]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 6. Build preprocessing pipeline\nX_train_preprocessed = preprocessor.fit_transform(X_train)\nX_val_preprocessed = preprocessor.transform(X_val)\nX_test_preprocessed = preprocessor.transform(X_test)\n\nprint(\"\\nFinal processed feature matrix shapes:\")\nprint(\"Train:\", X_train_preprocessed.shape)\nprint(\"Validation:\", X_val_preprocessed.shape)\nprint(\"Test:\", X_test_preprocessed.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:46:08.536315Z","iopub.execute_input":"2025-09-02T15:46:08.536621Z","iopub.status.idle":"2025-09-02T15:46:08.569813Z","shell.execute_reply.started":"2025-09-02T15:46:08.536601Z","shell.execute_reply":"2025-09-02T15:46:08.568845Z"}},"outputs":[{"name":"stdout","text":"\nFinal processed feature matrix shapes:\nTrain: (136, 35)\nValidation: (34, 35)\nTest: (43, 35)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import joblib\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Dictionary of models to train\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n    \"SVM (RBF Kernel)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n    \"Naive Bayes\": GaussianNB(),\n    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n}\n\nresults = {}\nbest_model = None\nbest_val_acc = 0\nbest_model_name = \"\"\n\n# =========================\n# Training loop\n# =========================\nfor name, model in models.items():\n    print(f\"\\nðŸ”¹ Training {name}...\")\n    model.fit(X_train_preprocessed, y_train)\n\n    # Validation performance\n    y_val_pred = model.predict(X_val_preprocessed)\n    val_acc = accuracy_score(y_val, y_val_pred)\n\n    # Test performance\n    y_test_pred = model.predict(X_test_preprocessed)\n    test_acc = accuracy_score(y_test, y_test_pred)\n\n    # Store results\n    results[name] = {\n        \"Validation Accuracy\": val_acc,\n        \"Test Accuracy\": test_acc,\n        \"Classification Report (Test)\": classification_report(y_test, y_test_pred, target_names=[\"Benign\",\"Malignant\"])\n    }\n\n    # Track best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_model = model\n        best_model_name = name\n\n# =========================\n# Results summary\n# =========================\nprint(\"\\n================= Model Comparison =================\")\nfor name, metrics in results.items():\n    print(f\"\\n{name}\")\n    print(f\"Validation Accuracy: {metrics['Validation Accuracy']:.4f}\")\n    print(f\"Test Accuracy: {metrics['Test Accuracy']:.4f}\")\n    print(metrics[\"Classification Report (Test)\"])\n\nprint(\"\\nâœ… Best model:\", best_model_name, f\"(Validation Accuracy: {best_val_acc:.4f})\")\n\n# =========================\n# Save best model\n# =========================\njoblib.dump(best_model, \"best_model.pkl\")\nprint(\"ðŸŽ‰ Best model saved as best_model.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:46:09.057081Z","iopub.execute_input":"2025-09-02T15:46:09.057433Z","iopub.status.idle":"2025-09-02T15:46:10.178018Z","shell.execute_reply.started":"2025-09-02T15:46:09.057410Z","shell.execute_reply":"2025-09-02T15:46:10.177036Z"}},"outputs":[{"name":"stdout","text":"\nðŸ”¹ Training Logistic Regression...\n\nðŸ”¹ Training Random Forest...\n\nðŸ”¹ Training SVM (RBF Kernel)...\n\nðŸ”¹ Training XGBoost...\n\nðŸ”¹ Training KNN...\n\nðŸ”¹ Training Naive Bayes...\n\nðŸ”¹ Training Gradient Boosting...\n\n================= Model Comparison =================\n\nLogistic Regression\nValidation Accuracy: 0.9706\nTest Accuracy: 0.9070\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.96      0.92        24\n   Malignant       0.94      0.84      0.89        19\n\n    accuracy                           0.91        43\n   macro avg       0.91      0.90      0.90        43\nweighted avg       0.91      0.91      0.91        43\n\n\nRandom Forest\nValidation Accuracy: 0.9706\nTest Accuracy: 0.8837\n              precision    recall  f1-score   support\n\n      Benign       0.85      0.96      0.90        24\n   Malignant       0.94      0.79      0.86        19\n\n    accuracy                           0.88        43\n   macro avg       0.89      0.87      0.88        43\nweighted avg       0.89      0.88      0.88        43\n\n\nSVM (RBF Kernel)\nValidation Accuracy: 0.9706\nTest Accuracy: 0.9070\n              precision    recall  f1-score   support\n\n      Benign       0.86      1.00      0.92        24\n   Malignant       1.00      0.79      0.88        19\n\n    accuracy                           0.91        43\n   macro avg       0.93      0.89      0.90        43\nweighted avg       0.92      0.91      0.91        43\n\n\nXGBoost\nValidation Accuracy: 0.8824\nTest Accuracy: 0.7907\n              precision    recall  f1-score   support\n\n      Benign       0.89      0.71      0.79        24\n   Malignant       0.71      0.89      0.79        19\n\n    accuracy                           0.79        43\n   macro avg       0.80      0.80      0.79        43\nweighted avg       0.81      0.79      0.79        43\n\n\nKNN\nValidation Accuracy: 0.9412\nTest Accuracy: 0.9070\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.96      0.92        24\n   Malignant       0.94      0.84      0.89        19\n\n    accuracy                           0.91        43\n   macro avg       0.91      0.90      0.90        43\nweighted avg       0.91      0.91      0.91        43\n\n\nNaive Bayes\nValidation Accuracy: 0.9706\nTest Accuracy: 0.9070\n              precision    recall  f1-score   support\n\n      Benign       0.88      0.96      0.92        24\n   Malignant       0.94      0.84      0.89        19\n\n    accuracy                           0.91        43\n   macro avg       0.91      0.90      0.90        43\nweighted avg       0.91      0.91      0.91        43\n\n\nGradient Boosting\nValidation Accuracy: 0.9118\nTest Accuracy: 0.7907\n              precision    recall  f1-score   support\n\n      Benign       0.86      0.75      0.80        24\n   Malignant       0.73      0.84      0.78        19\n\n    accuracy                           0.79        43\n   macro avg       0.79      0.80      0.79        43\nweighted avg       0.80      0.79      0.79        43\n\n\nâœ… Best model: Logistic Regression (Validation Accuracy: 0.9706)\nðŸŽ‰ Best model saved as best_model.pkl\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import joblib\n# Save the preprocessing pipeline\njoblib.dump(preprocessor, \"preprocessor.pkl\")\nprint(\"ðŸŽ‰ Preprocessing pipeline saved as preprocessor.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T15:46:10.271046Z","iopub.execute_input":"2025-09-02T15:46:10.271399Z","iopub.status.idle":"2025-09-02T15:46:10.281703Z","shell.execute_reply.started":"2025-09-02T15:46:10.271375Z","shell.execute_reply":"2025-09-02T15:46:10.280617Z"}},"outputs":[{"name":"stdout","text":"ðŸŽ‰ Preprocessing pipeline saved as preprocessor.pkl\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}